= MLPipeline (<ml_pipeline.MLPipeline object at 0x7fe1a655f0f0>) =
= MLPipeline (<ml_pipeline.MLPipeline object at 0x7fe1a655f0f0>): [1] Feature Preprocessing Stage =
= =============================== =

scaler: StandardScaler( scale=True mean=True )
features fitted and transformed
= =============================== =

= [2] Feature Selection Stage =
= =========================== =

3 selectors specified

[ VarianceThreshold ]
threshold: 0.16

[ SelectFromModel ]
median: 4.0
model: RFC

[ RFECV ]
median: 0.9
model: RFC

= Final feature selection =
selected features num: 10
selected features [
	loop-payload-fraction
	iterator-payload-total-cohesion
	iterator-payload-non-cf-cohesion
	payload-reg-dependencies-number
	payload-mem-read-fraction
	payload-call-count
	payload-call-fraction
	payload-branch-fraction
	payload-getelemptr-count
	payload-getelemptr-fraction
]
= =========================== =

= [3] Model Hyper-Parameter Selection Stage =
= ========================================= =

= Automatic model hyper-parameter selection =
method: GridSearchCV
model: RFC
= hyper-parameter grid search space =
n_estimators: 1 2 5 10 20 50 100 
max_depths: None 1 3 5 7 10 15 30 
min_samples_split: 0.05 0.1 0.2 0.5 0.7 0.9 
min_samples_leaf: 1 5 10 15 30 50 100 
= =
max_features: auto sqrt 

{'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 0.05, 'n_estimators': 20}
= ========================================= =

= [4] Model Training Stage =
= ======================== =

main model: RFC
[auto hyper-parameters search]
param: {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 0.05, 'n_estimators': 20}
= ======================== =

= MLPipeline (<ml_pipeline.MLPipeline object at 0x7fe1a655f0f0>) Prediction =
= ========================== =

stratified baseline tested
most_frequent baseline tested
prior baseline tested
uniform baseline tested
constant baseline tested
= ========================== =

= [6] Model Report Stage =
= ====================== =

==============================================================



